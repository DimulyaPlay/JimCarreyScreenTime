{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jim Carrey Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEFaMczL-Z-t"
      },
      "source": [
        "import os \n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda, Flatten, Reshape, Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, concatenate, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks  import ModelCheckpoint\n",
        "from moviepy.editor import * \n",
        "from natsort import natsorted\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHocYk25ViFl",
        "cellView": "form",
        "outputId": "c1cb15b8-999e-4f43-a4fc-1af88e4d5b67"
      },
      "source": [
        "#@title Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zHT1xSuT0H4x"
      },
      "source": [
        "#@title Local\n",
        "os.chdir(\"E:/\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYT2wFoC-wKd"
      },
      "source": [
        "## раскадровка фильмов для сбора базы. Ссылка на собранную базу https://drive.google.com/file/d/1MQ36P2OpQDoO62_nqkk7uuuKlPIcdCd5/view?usp=sharing\n",
        "\"\"\"\n",
        "count = 0                         \n",
        "imId = 'Лжец. лжец - 720HD - [ KinoMobi.net ].mp4'\n",
        "cap= cv2.VideoCapture(imId)\n",
        "frameRate = cap.get(5)*3\n",
        "image_folder = 'forsort'\n",
        "while cap.isOpened():\n",
        "  frameId = cap.get(1)\n",
        "  ret, frame = cap.read()\n",
        "  if (ret != True):\n",
        "    break\n",
        "  if (frameId % math.floor(frameRate) == 0):\n",
        "      filename =\"frameF%d.jpg\" % count;count+=1\n",
        "      cv2.imwrite(image_folder+'/'+ filename, frame)\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJrN93QMwrUa"
      },
      "source": [
        "!unzip -q '/content/drive/MyDrive/Базы/Jim.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-N9JYWjp75p",
        "outputId": "dacd9bef-c22a-4ba5-d383-b0b786529b0b"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split= 0.2, horizontal_flip=True, rotation_range=5)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory='/content/Jim', target_size=(224,224), subset='training', batch_size=64)\n",
        "val_generator = train_datagen.flow_from_directory(directory='/content/Jim', target_size=(224,224), subset='validation', batch_size=64)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9818 images belonging to 2 classes.\n",
            "Found 2454 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjhCSA_uu7fG"
      },
      "source": [
        "vgg_model = VGG16(include_top=False)\n",
        "vggModel = Model(vgg_model.input,vgg_model.output)\n",
        "\n",
        "inputs = Input(shape=(224,224,3))\n",
        "popOut = vggModel(inputs)\n",
        "flatten = Flatten()(popOut)\n",
        "dense1 = Dense(1024, activation = 'relu')(flatten)\n",
        "drop1 = Dropout(0.25)(dense1)\n",
        "dense2 = Dense(1024, activation = 'relu')(drop1)\n",
        "drop2 = Dropout(0.25)(dense2)\n",
        "outputs = Dense(2, activation = 'softmax')(drop2)\n",
        "model = Model(inputs, outputs)\n",
        "vggModel.trainable = False\n",
        "\n",
        "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "filepath=\"best_model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPYUmdCb0Fh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c200c8-4313-451a-beeb-bd0633ae2322"
      },
      "source": [
        "model.fit(train_generator,  epochs=10, validation_data=val_generator, callbacks = callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "154/154 [==============================] - 119s 767ms/step - loss: 0.8917 - accuracy: 0.7245 - val_loss: 0.5660 - val_accuracy: 0.7645\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76447, saving model to best_model.h5\n",
            "Epoch 2/10\n",
            "154/154 [==============================] - 119s 776ms/step - loss: 0.3185 - accuracy: 0.8615 - val_loss: 0.6689 - val_accuracy: 0.7698\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.76447 to 0.76976, saving model to best_model.h5\n",
            "Epoch 3/10\n",
            "154/154 [==============================] - 116s 754ms/step - loss: 0.2543 - accuracy: 0.8914 - val_loss: 0.6014 - val_accuracy: 0.7689\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.76976\n",
            "Epoch 4/10\n",
            "154/154 [==============================] - 117s 758ms/step - loss: 0.2213 - accuracy: 0.9105 - val_loss: 0.5788 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.76976\n",
            "Epoch 5/10\n",
            "154/154 [==============================] - 119s 773ms/step - loss: 0.2279 - accuracy: 0.9028 - val_loss: 0.5980 - val_accuracy: 0.7747\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.76976 to 0.77465, saving model to best_model.h5\n",
            "Epoch 6/10\n",
            "154/154 [==============================] - 117s 758ms/step - loss: 0.2616 - accuracy: 0.8878 - val_loss: 0.6740 - val_accuracy: 0.7441\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.77465\n",
            "Epoch 7/10\n",
            "154/154 [==============================] - 118s 766ms/step - loss: 0.2226 - accuracy: 0.9026 - val_loss: 0.6696 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.77465\n",
            "Epoch 8/10\n",
            " 13/154 [=>............................] - ETA: 1:26 - loss: 0.2467 - accuracy: 0.8882"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqwq5xGWK5KX",
        "outputId": "f8558711-f713-451f-be5a-504a05092521"
      },
      "source": [
        "model.save('E:\\content\\drive\\MyDrive\\TrainedModels\\jimVal80')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: E:\\content\\drive\\MyDrive\\TrainedModels\\jimVal80\\assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUfWoMUx891J"
      },
      "source": [
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeddfqRlwAtR"
      },
      "source": [
        "def take_frames_from_video_by_seconds(model, video_path, divide_sec_on):\n",
        "  second = 0 \n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  frameRate = cap.get(5)/divide_sec_on\n",
        "  image_folder = 'temp'\n",
        "  while cap.isOpened():\n",
        "    frameId = cap.get(1)\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "    if frameId%round(frameRate,0)==1:  \n",
        "      filename =f\"{round(second, 1)}.jpg\";second+=(1/round(frameRate,0))\n",
        "      cv2.imwrite(image_folder+'/'+ filename, cv2.resize(frame, (224,224)))\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  return round(frameRate,0)\n",
        "  \n",
        "def predict_from_frames(frameRate, model=model, path='temp'):\n",
        "  counter = 0\n",
        "  predict = []\n",
        "  temp = []\n",
        "  for filename in tqdm(natsorted(os.listdir(path))):\n",
        "\n",
        "      img = cv2.imread(path+'/'+filename)\n",
        "      img = img/255.\n",
        "      pred = model.predict(img[None, :,:,:])\n",
        "      temp.append(np.argmax(pred[0]))\n",
        "      counter+=1\n",
        "      if counter>=frameRate:\n",
        "        predict.append(temp)\n",
        "        temp = []\n",
        "        counter = 0\n",
        "  return np.array(predict)\n",
        "\n",
        "def get_timings_from_predict(predict, frameRate):\n",
        "  seconds = []\n",
        "  for s, pred in enumerate(predict):\n",
        "    if sum(pred)<frameRate*0.4:\n",
        "      seconds.append(s)\n",
        "  return seconds\n",
        "\n",
        "def preprocess_timings(list_of_seconds, bias): # bias - разница между планами. Не разрезать кусок видео, если между от джима до джима промежуток bias секунд(0 - полная нетерпимость к отсутствию джима)\n",
        "  time_list = []\n",
        "  temp = []\n",
        "  for i in range(len(list_of_seconds)-1):\n",
        "    temp.append(list_of_seconds[i])\n",
        "    if list_of_seconds[i+1]-list_of_seconds[i]>bias+1:\n",
        "      time_list.append([temp[0], temp[-1]+1])\n",
        "      temp = []\n",
        "  return time_list\n",
        "\n",
        "def extract_samples(filepath, time_list):\n",
        "  for timings in time_list:\n",
        "    clip = VideoFileClip(filepath) \n",
        "    clip = clip.subclip(timings[0], timings[1]) \n",
        "    clip.write_videofile(filename = f\"cut/{timings[0]}.mp4\")\n",
        "    clear_output()\n",
        "    clip.close()\n",
        "\n",
        "def make_one_clip_from_cuts(cutdir=\"cut/\"):\n",
        "  clips =[]\n",
        "  for root, dirs, files in os.walk(cutdir):\n",
        "      files = natsorted(files)\n",
        "      for file in tqdm(files):\n",
        "        filePath = os.path.join(root, file)\n",
        "        video = VideoFileClip(filePath)\n",
        "        clips.append(video)\n",
        "  final_clip = concatenate_videoclips(clips)\n",
        "  final_clip.write_videofile('output.mp4', logger=None, verbose=False)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Ta4gnH2E7Z"
      },
      "source": [
        "def main(filepath,model=model, fps_division = 5, bias = 1):\n",
        "  try: os.mkdir('temp'); os.mkdir('cut')\n",
        "  except Exception:\n",
        "    pass\n",
        "  print('Подготовка к распознаванию')\n",
        "  divided_fps = take_frames_from_video_by_seconds(model, filepath, fps_division)\n",
        "  clear_output()\n",
        "  print('Распознавание')\n",
        "  predict = predict_from_frames(divided_fps)\n",
        "  clear_output()\n",
        "  print('Расчет длительности клипа')\n",
        "  seconds = get_timings_from_predict(predict, divided_fps)\n",
        "  time_list = preprocess_timings(seconds, bias)\n",
        "  clear_output()\n",
        "  print('Нарезка клипов')\n",
        "  extract_samples(filepath, time_list)\n",
        "  clear_output()\n",
        "  print('Склеивание клипов. Расчетное время Джима в кадре:',round(len(seconds)/60,0), \"минут\", len(seconds)%60, 'секунд')\n",
        "  make_one_clip_from_cuts()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vxxQR4k9ORO",
        "outputId": "15b6f759-86f8-4e9f-d5cf-c364c4a37fe9"
      },
      "source": [
        "main('Shou_Trumana_Kinosimka.RU (online-video-cutter.com).mp4')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|                                                                                          | 0/127 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Склеивание клипов. Расчетное время Джима в кадре: 9.0 минут 44 секунд\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:25<00:00,  4.94it/s]\n",
            "chunk:   0%|▎                                                            | 69/15090 [00:00<00:42, 351.49it/s, now=None]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Moviepy - Building video __temp__.mp4.\n",
            "MoviePy - Writing audio in __temp__TEMP_MPY_wvf_snd.mp3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "t:   0%|                                                                 | 28/16408 [00:00<00:59, 277.22it/s, now=None]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video __temp__.mp4\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready __temp__.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}